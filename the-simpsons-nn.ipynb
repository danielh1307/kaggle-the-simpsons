{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T19:45:38.008575500Z",
     "start_time": "2023-09-27T19:45:37.976811400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "# device = \"cpu\" # uncomment if you want to use \"cpu\", currently cpu is faster than cuda (maybe because the NN is very little)\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T19:45:38.408064400Z",
     "start_time": "2023-09-27T19:45:38.395661200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T19:45:39.294990600Z",
     "start_time": "2023-09-27T19:45:39.275001100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading an image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Functions for image handling\n",
    "\n",
    "def show_image_by_path(_image_path: str) -> None:\n",
    "    image = Image.open(_image_path)\n",
    "    image.show()\n",
    "\n",
    "def image_to_tensor(_image_path: str) -> torch.Tensor:\n",
    "    image = Image.open(_image_path)\n",
    "\n",
    "    transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomRotation(15),\n",
    "                                    transforms.ToTensor()])\n",
    "    _image_tensor = transform(image)  # image_tensor now has a shape of torch.Size([3, 224, 224])\n",
    "\n",
    "    # RandomHorizontalFlip\n",
    "    # --> randomly mirror the image from the left to right\n",
    "    # RandomRotation\n",
    "    # --> rotate the image by a random angle within a given range, in this case from -15 to +15 degrees\n",
    "\n",
    "    # we add a batch dimension since most neural network frameworks expect input in the form of batches\n",
    "    # the batch dimension helps in parallel processing and is essential for training the model with\n",
    "    # multiple samples\n",
    "    _image_tensor = _image_tensor.unsqueeze(0)  # image_tensor now has a shape of torch.Size([1, 3, 224, 224])\n",
    "\n",
    "    # image_tensor now has these dimensions: [batch_size, channels, height, width]\n",
    "    # the channel dimension refers to the different color layers that make up an image. Usually, we have 3 channels: RGB\n",
    "    # by using transforms.ToTensor(), we automatically normalize the pixel values to a range between 0 and 1 (instead of 0 to 255).\n",
    "    # it is important to understand each value in the multidimensional array is between 0 and 1 now\n",
    "\n",
    "    return _image_tensor\n",
    "\n",
    "def show_image_by_tensor(_image_tensor: torch.Tensor) -> None:\n",
    "    _image_tensor = _image_tensor.squeeze(0)  # remove the batch dimension\n",
    "    transform = transforms.Compose([transforms.ToPILImage()])\n",
    "\n",
    "    # convert tensor to PIL image\n",
    "    image_pil = transform(_image_tensor)\n",
    "\n",
    "    # display the image\n",
    "    image_pil.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T19:45:59.928785100Z",
     "start_time": "2023-09-27T19:45:59.913754100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "image_path = \"data/simpsons_dataset/abraham_grampa_simpson/pic_0000.jpg\"\n",
    "show_image_by_path(image_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T19:45:44.284740900Z",
     "start_time": "2023-09-27T19:45:40.864322800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 224, 224])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor = image_to_tensor(image_path)\n",
    "image_tensor.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T19:45:45.869056700Z",
     "start_time": "2023-09-27T19:45:45.857068600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "show_image_by_tensor(image_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T19:46:05.019707900Z",
     "start_time": "2023-09-27T19:46:01.634218300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
