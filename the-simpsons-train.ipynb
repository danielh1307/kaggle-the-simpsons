{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (0.15.11)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from wandb) (3.1.37)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from wandb) (1.31.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from wandb) (68.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from wandb) (4.24.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:18:52.050777500Z",
     "start_time": "2023-09-30T13:18:50.202398900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\Scripts\\wandb.exe\\__main__.py\", line 7, in <module>\n",
      "    sys.exit(cli())\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages\\click\\core.py\", line 1157, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages\\click\\core.py\", line 1078, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages\\click\\core.py\", line 1688, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages\\click\\core.py\", line 1434, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages\\click\\core.py\", line 783, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages\\wandb\\cli\\cli.py\", line 102, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages\\wandb\\cli\\cli.py\", line 246, in login\n",
      "    wandb.login(relogin=relogin, key=key, anonymous=anon_mode, host=host, force=True)\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages\\wandb\\sdk\\wandb_login.py\", line 77, in login\n",
      "    configured = _login(**kwargs)\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages\\wandb\\sdk\\wandb_login.py\", line 292, in _login\n",
      "    wlogin.configure_api_key(key)\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages\\wandb\\sdk\\wandb_login.py\", line 176, in configure_api_key\n",
      "    apikey.write_key(self._settings, key)\n",
      "  File \"C:\\Users\\hammd\\miniconda3\\envs\\kaggle-the-simpsons-env\\lib\\site-packages\\wandb\\sdk\\lib\\apikey.py\", line 239, in write_key\n",
      "    raise ValueError(\"API key must be 40 characters long, yours was %s\" % len(key))\n",
      "ValueError: API key must be 40 characters long, yours was 7\n"
     ]
    }
   ],
   "source": [
    "!wandb login API-KEY"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:19:14.489320900Z",
     "start_time": "2023-09-30T13:19:11.356584900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from simpsons_neural_network_1 import SimpsonsNet1\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import wandb\n",
    "import argparse\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:19:18.464596700Z",
     "start_time": "2023-09-30T13:19:14.487291700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check if we can use Cuda"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "# device = \"cpu\" # uncomment if you want to use \"cpu\", currently cpu is faster than cuda (maybe because the NN is very little)\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:19:20.626537900Z",
     "start_time": "2023-09-30T13:19:20.558537800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initialize wandb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "config = argparse.Namespace()\n",
    "config.learning_rate = 0.01\n",
    "config.epochs = 30\n",
    "config.batch_size = 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:19:22.093316500Z",
     "start_time": "2023-09-30T13:19:22.085286200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating a custom Dataset Class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class SimpsonsImageDataset(Dataset):\n",
    "    def __init__(self, tensor, label):\n",
    "        self.tensor = tensor\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tensor[index], self.label[index]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:19:23.285644Z",
     "start_time": "2023-09-30T13:19:23.265611900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading an image and creating a label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "all_labels = [\"abraham_grampa_simpson\",\n",
    "              \"agnes_skinner\",\n",
    "              \"apu_nahasapeemapetilon\",\n",
    "              \"barney_gumble\",\n",
    "              \"bart_simpson\",\n",
    "              \"carl_carlson\",\n",
    "              \"charles_montgomery_burns\",\n",
    "              \"chief_wiggum\",\n",
    "              \"cletus_spuckler\",\n",
    "              \"comic_book_guy\",\n",
    "              \"disco_stu\",\n",
    "              \"edna_krabappel\",\n",
    "              \"fat_tony\",\n",
    "              \"gil\",\n",
    "              \"groundskeeper_willie\",\n",
    "              \"homer_simpson\",\n",
    "              \"kent_brockman\",\n",
    "              \"krusty_the_clown\",\n",
    "              \"lenny_leonard\",\n",
    "              \"lionel_hutz\",\n",
    "              \"lisa_simpson\",\n",
    "              \"maggie_simpson\",\n",
    "              \"marge_simpson\",\n",
    "              \"martin_prince\",\n",
    "              \"mayor_quimby\",\n",
    "              \"milhouse_van_houten\",\n",
    "              \"miss_hoover\",\n",
    "              \"moe_szyslak\",\n",
    "              \"ned_flanders\"\n",
    "              ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:19:24.301670400Z",
     "start_time": "2023-09-30T13:19:24.291669300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Functions for image handling\n",
    "\n",
    "def show_image_by_path(_image_path: str) -> None:\n",
    "    image = Image.open(_image_path)\n",
    "    image.show()\n",
    "\n",
    "def image_to_tensor(_image_path: str) -> torch.Tensor:\n",
    "    image = Image.open(_image_path)\n",
    "\n",
    "    transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomRotation(15),\n",
    "                                    transforms.ToTensor()])\n",
    "    _image_tensor = transform(image)  # image_tensor now has a shape of torch.Size([3, 224, 224])\n",
    "\n",
    "    # RandomHorizontalFlip\n",
    "    # --> randomly mirror the image from the left to right\n",
    "    # RandomRotation\n",
    "    # --> rotate the image by a random angle within a given range, in this case from -15 to +15 degrees\n",
    "\n",
    "    # we add a batch dimension since most neural network frameworks expect input in the form of batches\n",
    "    # the batch dimension helps in parallel processing and is essential for training the model with\n",
    "    # multiple samples\n",
    "    # _image_tensor = _image_tensor.unsqueeze(0)  # image_tensor now has a shape of torch.Size([1, 3, 224, 224])\n",
    "\n",
    "    # image_tensor now has these dimensions: [batch_size, channels, height, width]\n",
    "    # the channel dimension refers to the different color layers that make up an image. Usually, we have 3 channels: RGB\n",
    "    # by using transforms.ToTensor(), we automatically normalize the pixel values to a range between 0 and 1 (instead of 0 to 255).\n",
    "    # it is important to understand each value in the multidimensional array is between 0 and 1 now\n",
    "\n",
    "    return _image_tensor.to(device)\n",
    "\n",
    "def show_image_by_tensor(_image_tensor: torch.Tensor) -> None:\n",
    "    _image_tensor = _image_tensor.squeeze(0)  # remove the batch dimension\n",
    "    transform = transforms.Compose([transforms.ToPILImage()])\n",
    "\n",
    "    # convert tensor to PIL image\n",
    "    image_pil = transform(_image_tensor)\n",
    "\n",
    "    # display the image\n",
    "    image_pil.show()\n",
    "\n",
    "\n",
    "def get_label_for_image_path(_image_path: str) -> torch.Tensor:\n",
    "    # here we are returning a tensor with just one dimension - it is equal to the size of the batch dimension of a single image\n",
    "    # depending on the image_path, a label tensor with value between 0 and 19 is created (since we have 20 different characters)\n",
    "    directory = os.path.basename(os.path.dirname(_image_path))\n",
    "    label_idx = all_labels.index(directory)\n",
    "    return torch.tensor(label_idx, dtype=torch.long).to(device)\n",
    "\n",
    "def get_character_for_label(_label_tensor: str) -> str:\n",
    "    return all_labels[_label_tensor[0]]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:19:24.881926900Z",
     "start_time": "2023-09-30T13:19:24.862925600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder data/train\\abraham_grampa_simpson\n",
      "Processing folder data/train\\agnes_skinner\n",
      "Processing folder data/train\\apu_nahasapeemapetilon\n",
      "Processing folder data/train\\barney_gumble\n",
      "Processing folder data/train\\bart_simpson\n",
      "Processing folder data/train\\carl_carlson\n",
      "Processing folder data/train\\charles_montgomery_burns\n",
      "Processing folder data/train\\chief_wiggum\n",
      "Processing folder data/train\\cletus_spuckler\n",
      "Processing folder data/train\\comic_book_guy\n",
      "Processing folder data/train\\disco_stu\n",
      "Processing folder data/train\\edna_krabappel\n",
      "Processing folder data/train\\fat_tony\n",
      "Processing folder data/train\\gil\n",
      "Processing folder data/train\\groundskeeper_willie\n",
      "Processing folder data/train\\homer_simpson\n",
      "Processing folder data/train\\kent_brockman\n",
      "Processing folder data/train\\krusty_the_clown\n",
      "Processing folder data/train\\lenny_leonard\n",
      "Processing folder data/train\\lionel_hutz\n",
      "Processing folder data/train\\lisa_simpson\n",
      "Processing folder data/train\\maggie_simpson\n",
      "Processing folder data/train\\marge_simpson\n",
      "Processing folder data/train\\martin_prince\n",
      "Processing folder data/train\\mayor_quimby\n",
      "Processing folder data/train\\milhouse_van_houten\n",
      "Processing folder data/train\\miss_hoover\n",
      "Processing folder data/train\\moe_szyslak\n",
      "Processing folder data/train\\ned_flanders\n",
      "Finished processing, got 17026 image tensors and 17026 label tensors\n"
     ]
    }
   ],
   "source": [
    "image_tensors = []\n",
    "label_tensors = []\n",
    "\n",
    "root_dir = \"data/train\"\n",
    "\n",
    "for character in os.listdir(root_dir):\n",
    "    char_dir = os.path.join(root_dir, character)\n",
    "\n",
    "    # check if it's a folder\n",
    "    if os.path.isdir(char_dir):\n",
    "        print(f\"Processing folder {char_dir}\")\n",
    "\n",
    "        # iterate through all the files\n",
    "        for filename in os.listdir(char_dir):\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                img_path = os.path.join(char_dir, filename)\n",
    "\n",
    "                # load the tensor and the label for the image\n",
    "                image_tensor = image_to_tensor(img_path)\n",
    "                label_tensor = get_label_for_image_path(img_path)\n",
    "\n",
    "                # append to list\n",
    "                image_tensors.append(image_tensor)\n",
    "                label_tensors.append(label_tensor)\n",
    "\n",
    "print(f\"Finished processing, got {len(image_tensors)} image tensors and {len(label_tensors)} label tensors\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:20:26.378803Z",
     "start_time": "2023-09-30T13:19:25.474612700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "image_tensor_combined = torch.stack(image_tensors)\n",
    "label_tensor_combined = torch.stack(label_tensors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:20:57.990378700Z",
     "start_time": "2023-09-30T13:20:55.617145300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "simpsons_dataset = SimpsonsImageDataset(image_tensor_combined, label_tensor_combined)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:20:58.877655900Z",
     "start_time": "2023-09-30T13:20:58.846613500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Splitting into train and test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am using 13620 images for training and 3406 images for validation\n"
     ]
    }
   ],
   "source": [
    "total_size = len(simpsons_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "validation_size = total_size - train_size\n",
    "\n",
    "train_dataset, validation_dataset = random_split(simpsons_dataset, [train_size, validation_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "print(f\"I am using {len(train_dataset)} images for training and {len(validation_dataset)} images for validation\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:21:00.793589200Z",
     "start_time": "2023-09-30T13:21:00.786584100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Network Architecture, loss function and optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpsonsNet1(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=50176, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=29, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create a complete CNN\n",
    "model = SimpsonsNet1()\n",
    "config.model = model.__class__\n",
    "print(model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate)\n",
    "# adding a scheduler to reduce the learning_rate as soon as the validation loss stops decreasing.\n",
    "# this is to try to prevent overfitting of the model\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min')  # 'min' means reducing the LR when the metric stops decreasing\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:21:03.997147800Z",
     "start_time": "2023-09-30T13:21:03.879140700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mhamm-daniel\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.11"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\dev\\projects\\kaggle-the-simpsons\\wandb\\run-20230930_152108-1c2ehxl7</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/hamm-daniel/kaggle-simpsons/runs/1c2ehxl7' target=\"_blank\">breezy-resonance-6</a></strong> to <a href='https://wandb.ai/hamm-daniel/kaggle-simpsons' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/hamm-daniel/kaggle-simpsons' target=\"_blank\">https://wandb.ai/hamm-daniel/kaggle-simpsons</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/hamm-daniel/kaggle-simpsons/runs/1c2ehxl7' target=\"_blank\">https://wandb.ai/hamm-daniel/kaggle-simpsons/runs/1c2ehxl7</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hamm-daniel/kaggle-simpsons/runs/1c2ehxl7?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x1237f243c70>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"kaggle-simpsons\", config=vars(config))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T13:21:09.479111Z",
     "start_time": "2023-09-30T13:21:05.478457700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 1, Train Loss: 2.8682481453452313, Validation Loss: 2.7148306993680578\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 2, Train Loss: 2.5341141568103307, Validation Loss: 2.409769780167909\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 3, Train Loss: 2.252490165088098, Validation Loss: 2.1811372710165577\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 4, Train Loss: 2.0163096402172753, Validation Loss: 1.9599462658445412\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 5, Train Loss: 1.8310439404747296, Validation Loss: 1.8671481720755034\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 6, Train Loss: 1.6745801895437107, Validation Loss: 1.7386216159178831\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 7, Train Loss: 1.5485102513306577, Validation Loss: 1.7183684712258456\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 8, Train Loss: 1.4277806501713157, Validation Loss: 1.6435927431160045\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 9, Train Loss: 1.2802928372727873, Validation Loss: 1.5586321047533338\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 10, Train Loss: 1.1365340804689927, Validation Loss: 1.5167651638806423\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 11, Train Loss: 0.9707658002634003, Validation Loss: 1.4416097753515869\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 12, Train Loss: 0.825624641957977, Validation Loss: 1.4223179700218629\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 13, Train Loss: 0.6788121118721827, Validation Loss: 1.44437130088004\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 14, Train Loss: 0.5449104107951335, Validation Loss: 1.427544657872102\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 15, Train Loss: 0.41639754585397076, Validation Loss: 1.596581816116226\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 16, Train Loss: 0.3285296053009134, Validation Loss: 1.6388395345099618\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 17, Train Loss: 0.25710386213597275, Validation Loss: 1.6197117528068685\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 18, Train Loss: 0.2094681996922118, Validation Loss: 1.669994920213646\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 19, Train Loss: 0.1686288027000994, Validation Loss: 1.6769564229751301\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 20, Train Loss: 0.1436274417702266, Validation Loss: 1.6815422110468428\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 21, Train Loss: 0.13552385203850767, Validation Loss: 1.8806354141680994\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 22, Train Loss: 0.11149576655042494, Validation Loss: 1.7365988041752967\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 23, Train Loss: 0.09452133350830717, Validation Loss: 1.7944549567231507\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 24, Train Loss: 0.051818866689335295, Validation Loss: 1.7574528773254323\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 25, Train Loss: 0.03909335200539014, Validation Loss: 1.7810921691288457\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 26, Train Loss: 0.033971523364460396, Validation Loss: 1.7795605336394265\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 27, Train Loss: 0.02993226627723047, Validation Loss: 1.8000200585784198\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 28, Train Loss: 0.027932442372794342, Validation Loss: 1.8203265382864764\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 29, Train Loss: 0.027917318153900132, Validation Loss: 1.8106878706227953\n",
      "batch 0 from 426 ...\n",
      "batch 50 from 426 ...\n",
      "batch 100 from 426 ...\n",
      "batch 150 from 426 ...\n",
      "batch 200 from 426 ...\n",
      "batch 250 from 426 ...\n",
      "batch 300 from 426 ...\n",
      "batch 350 from 426 ...\n",
      "batch 400 from 426 ...\n",
      "Epoch 30, Train Loss: 0.027779757571947748, Validation Loss: 1.8159929647623936\n"
     ]
    }
   ],
   "source": [
    "wandb.watch(model)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, config.epochs + 1):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    batch_number = 0\n",
    "    for images, labels in train_loader:\n",
    "        if batch_number % 50 == 0:\n",
    "            print(f\"batch {batch_number} from {len(train_loader)} ...\")\n",
    "        batch_number += 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)  # output shape: torch.Size([32, 29])\n",
    "        # the first dimension has a size of 32 due to our batch size (changes with different batch sizes)\n",
    "        # second dimension is 29 because we have 29 output labels\n",
    "\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            output = model(images)\n",
    "            loss = loss_function(output, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # step the scheduler - adjust the learning rate if validation loss stops decresing\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch}, Train Loss: {train_loss/len(train_loader)}, Validation Loss: {val_loss/len(validation_loader)}\")\n",
    "    wandb.log({'epoch': epoch, 'training loss': train_loss, 'validation loss': val_loss, 'adjusted learning rate': optimizer.param_groups[0]['lr']})\n",
    "\n",
    "    # Save model if validation loss has decreased\n",
    "    if val_loss < best_val_loss:\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        best_val_loss = val_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T14:43:17.231599400Z",
     "start_time": "2023-09-30T13:21:21.335333400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d052f2d605d5463da764192256d7f6b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>adjusted learning rate</td><td>██████████████████████▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>training loss</td><td>█▇▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation loss</td><td>█▆▅▄▃▃▃▂▂▂▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>adjusted learning rate</td><td>0.001</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>training loss</td><td>11.83418</td></tr><tr><td>validation loss</td><td>194.31125</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">breezy-resonance-6</strong> at: <a href='https://wandb.ai/hamm-daniel/kaggle-simpsons/runs/1c2ehxl7' target=\"_blank\">https://wandb.ai/hamm-daniel/kaggle-simpsons/runs/1c2ehxl7</a><br/> View job at <a href='https://wandb.ai/hamm-daniel/kaggle-simpsons/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwMjc0MTY3MA==/version_details/v0' target=\"_blank\">https://wandb.ai/hamm-daniel/kaggle-simpsons/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwMjc0MTY3MA==/version_details/v0</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20230930_152108-1c2ehxl7\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
