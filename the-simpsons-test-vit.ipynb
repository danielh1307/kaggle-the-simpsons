{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from shared_methods import all_labels, show_image_by_path\n",
    "from huggingface_pretrained import get_vision_transformer\n",
    "\n",
    "from transformers import ViTImageProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check if we can use Cuda"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "# device = \"cpu\" # uncomment if you want to use \"cpu\", currently cpu is faster than cuda (maybe because the NN is very little)\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_id = \"miig6ldy\"\n",
    "\n",
    "model = get_vision_transformer()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(f\"trained_models/vit_{run_id}_6.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Load the feature extractor (preprocessor)\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    path = \"data/test/461179.jpg\"\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    outputs = model(**inputs)  # Run inference\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predicted_label_idx = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    print(f\"I guess this is {all_labels[predicted_label_idx]}\")\n",
    "    show_image_by_path(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference method 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting batch 1 of 29\n",
      "Predicting batch 2 of 29\n",
      "Predicting batch 3 of 29\n",
      "Predicting batch 4 of 29\n",
      "Predicting batch 5 of 29\n",
      "Predicting batch 6 of 29\n",
      "Predicting batch 7 of 29\n",
      "Predicting batch 8 of 29\n",
      "Predicting batch 9 of 29\n",
      "Predicting batch 10 of 29\n",
      "Predicting batch 11 of 29\n",
      "Predicting batch 12 of 29\n",
      "Predicting batch 13 of 29\n",
      "Predicting batch 14 of 29\n",
      "Predicting batch 15 of 29\n",
      "Predicting batch 16 of 29\n",
      "Predicting batch 17 of 29\n",
      "Predicting batch 18 of 29\n",
      "Predicting batch 19 of 29\n",
      "Predicting batch 20 of 29\n",
      "Predicting batch 21 of 29\n",
      "Predicting batch 22 of 29\n",
      "Predicting batch 23 of 29\n",
      "Predicting batch 24 of 29\n",
      "Predicting batch 25 of 29\n",
      "Predicting batch 26 of 29\n",
      "Predicting batch 27 of 29\n",
      "Predicting batch 28 of 29\n",
      "Predicting batch 29 of 29\n",
      "Predicting batch 30 of 29\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"data/test\"\n",
    "batch_size = 32\n",
    "\n",
    "all_files = [f for f in os.listdir(root_dir) if f.endswith(\".jpg\")]\n",
    "num_batches = len(all_files) // batch_size\n",
    "\n",
    "with open(f\"solutions/solution_no1_{run_id}.csv\", \"w\") as output_file:\n",
    "    output_file.write(\"Id,Category\\n\")\n",
    "\n",
    "    # This loop iterates over the list of all test image files in batches. The step size is batch_size.\n",
    "    for i in range(0, len(all_files), batch_size):\n",
    "        print(f\"Predicting batch {i // batch_size + 1} of {num_batches}\")\n",
    "\n",
    "        # taking files from i to (i + batch_size)\n",
    "        batch_files = all_files[i:i + batch_size]\n",
    "        batch_tensors = [processor(Image.open(os.path.join(root_dir, f)).convert(\"RGB\"), return_tensors=\"pt\")['pixel_values'] for f in batch_files]\n",
    "\n",
    "        # stack along a new dimension\n",
    "        batch_tensors = torch.stack(batch_tensors).squeeze(1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch_tensors.to(device))['logits']\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            predicted_indices = torch.argmax(probabilities, dim=1)  # shape ([32]) -> label for each element in the batch\n",
    "\n",
    "        for j, predicted_index in enumerate(predicted_indices):\n",
    "            output_file.write(f\"{batch_files[j]},{all_labels[predicted_index.item()]}\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T07:55:31.042194Z",
     "start_time": "2023-10-05T07:55:16.487007100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference method 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting file with index 0\n",
      "Predicting file with index 10\n",
      "Predicting file with index 20\n",
      "Predicting file with index 30\n",
      "Predicting file with index 40\n",
      "Predicting file with index 50\n",
      "Predicting file with index 60\n",
      "Predicting file with index 70\n",
      "Predicting file with index 80\n",
      "Predicting file with index 90\n",
      "Predicting file with index 100\n",
      "Predicting file with index 110\n",
      "Predicting file with index 120\n",
      "Predicting file with index 130\n",
      "Predicting file with index 140\n",
      "Predicting file with index 150\n",
      "Predicting file with index 160\n",
      "Predicting file with index 170\n",
      "Predicting file with index 180\n",
      "Predicting file with index 190\n",
      "Predicting file with index 200\n",
      "Predicting file with index 210\n",
      "Predicting file with index 220\n",
      "Predicting file with index 230\n",
      "Predicting file with index 240\n",
      "Predicting file with index 250\n",
      "Predicting file with index 260\n",
      "Predicting file with index 270\n",
      "Predicting file with index 280\n",
      "Predicting file with index 290\n",
      "Predicting file with index 300\n",
      "Predicting file with index 310\n",
      "Predicting file with index 320\n",
      "Predicting file with index 330\n",
      "Predicting file with index 340\n",
      "Predicting file with index 350\n",
      "Predicting file with index 360\n",
      "Predicting file with index 370\n",
      "Predicting file with index 380\n",
      "Predicting file with index 390\n",
      "Predicting file with index 400\n",
      "Predicting file with index 410\n",
      "Predicting file with index 420\n",
      "Predicting file with index 430\n",
      "Predicting file with index 440\n",
      "Predicting file with index 450\n",
      "Predicting file with index 460\n",
      "Predicting file with index 470\n",
      "Predicting file with index 480\n",
      "Predicting file with index 490\n",
      "Predicting file with index 500\n",
      "Predicting file with index 510\n",
      "Predicting file with index 520\n",
      "Predicting file with index 530\n",
      "Predicting file with index 540\n",
      "Predicting file with index 550\n",
      "Predicting file with index 560\n",
      "Predicting file with index 570\n",
      "Predicting file with index 580\n",
      "Predicting file with index 590\n",
      "Predicting file with index 600\n",
      "Predicting file with index 610\n",
      "Predicting file with index 620\n",
      "Predicting file with index 630\n",
      "Predicting file with index 640\n",
      "Predicting file with index 650\n",
      "Predicting file with index 660\n",
      "Predicting file with index 670\n",
      "Predicting file with index 680\n",
      "Predicting file with index 690\n",
      "Predicting file with index 700\n",
      "Predicting file with index 710\n",
      "Predicting file with index 720\n",
      "Predicting file with index 730\n",
      "Predicting file with index 740\n",
      "Predicting file with index 750\n",
      "Predicting file with index 760\n",
      "Predicting file with index 770\n",
      "Predicting file with index 780\n",
      "Predicting file with index 790\n",
      "Predicting file with index 800\n",
      "Predicting file with index 810\n",
      "Predicting file with index 820\n",
      "Predicting file with index 830\n",
      "Predicting file with index 840\n",
      "Predicting file with index 850\n",
      "Predicting file with index 860\n",
      "Predicting file with index 870\n",
      "Predicting file with index 880\n",
      "Predicting file with index 890\n",
      "Predicting file with index 900\n",
      "Predicting file with index 910\n",
      "Predicting file with index 920\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"data/test\"\n",
    "\n",
    "output_file = open(f\"solutions/solution_no2_{run_id}.csv\", \"w\")\n",
    "output_file.write(\"Id,Category\\n\")\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for filename in os.listdir(root_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"Predicting file with index {idx}\")\n",
    "        idx += 1\n",
    "\n",
    "        img_path = os.path.join(root_dir, filename)\n",
    "        input_tensor = processor(Image.open(img_path).convert(\"RGB\"), return_tensors=\"pt\")['pixel_values'].to(device)\n",
    "        output = model(input_tensor)['logits']\n",
    "\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "        predicted_label_idx = torch.argmax(probabilities).item()\n",
    "\n",
    "        output_file.write(f\"{filename},{all_labels[predicted_label_idx]}\\n\")\n",
    "\n",
    "output_file.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T07:55:09.251748900Z",
     "start_time": "2023-10-05T07:54:48.737951100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
