{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-01T09:04:27.261026400Z",
     "start_time": "2023-10-01T09:04:27.239026200Z"
    }
   },
   "outputs": [],
   "source": [
    "from simpsons_neural_network_1 import SimpsonsNet1\n",
    "\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check if we can use Cuda"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "# device = \"cpu\" # uncomment if you want to use \"cpu\", currently cpu is faster than cuda (maybe because the NN is very little)\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T09:04:28.099397800Z",
     "start_time": "2023-10-01T09:04:28.087300200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Some general methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "all_labels = [\"abraham_grampa_simpson\",\n",
    "              \"agnes_skinner\",\n",
    "              \"apu_nahasapeemapetilon\",\n",
    "              \"barney_gumble\",\n",
    "              \"bart_simpson\",\n",
    "              \"carl_carlson\",\n",
    "              \"charles_montgomery_burns\",\n",
    "              \"chief_wiggum\",\n",
    "              \"cletus_spuckler\",\n",
    "              \"comic_book_guy\",\n",
    "              \"disco_stu\",\n",
    "              \"edna_krabappel\",\n",
    "              \"fat_tony\",\n",
    "              \"gil\",\n",
    "              \"groundskeeper_willie\",\n",
    "              \"homer_simpson\",\n",
    "              \"kent_brockman\",\n",
    "              \"krusty_the_clown\",\n",
    "              \"lenny_leonard\",\n",
    "              \"lionel_hutz\",\n",
    "              \"lisa_simpson\",\n",
    "              \"maggie_simpson\",\n",
    "              \"marge_simpson\",\n",
    "              \"martin_prince\",\n",
    "              \"mayor_quimby\",\n",
    "              \"milhouse_van_houten\",\n",
    "              \"miss_hoover\",\n",
    "              \"moe_szyslak\",\n",
    "              \"ned_flanders\"\n",
    "              ]\n",
    "\n",
    "def image_to_tensor(_image_path: str) -> torch.Tensor:\n",
    "    image = Image.open(_image_path)\n",
    "\n",
    "    transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                    #transforms.RandomHorizontalFlip(),\n",
    "                                    #transforms.RandomRotation(15),\n",
    "                                    transforms.ToTensor()])\n",
    "    _image_tensor = transform(image)\n",
    "\n",
    "    return _image_tensor.to(device)\n",
    "\n",
    "def show_image_by_path(_image_path: str) -> None:\n",
    "    image = Image.open(_image_path)\n",
    "    image.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T09:04:29.038236500Z",
     "start_time": "2023-10-01T09:04:29.016205900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = \"1c2ehxl7\"\n",
    "\n",
    "model = SimpsonsNet1()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(f\"trained_models/simpsons_net_1_{run_id}_2.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T09:04:47.326743Z",
     "start_time": "2023-10-01T09:04:47.179713400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I guess this is chief_wiggum\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    path = \"data/test/461179.jpg\"\n",
    "    input_tensor = image_to_tensor(path)\n",
    "    output = model(input_tensor)  # Run inference\n",
    "\n",
    "    # output tensor has shape [1, 29]\n",
    "    # one batch dimension for my single image and 29 class scores\n",
    "\n",
    "    probabilities = F.softmax(output, dim=1)\n",
    "    predicted_label_idx = torch.argmax(probabilities).item()\n",
    "\n",
    "    print(f\"I guess this is {all_labels[predicted_label_idx]}\")\n",
    "    show_image_by_path(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T09:04:53.319719300Z",
     "start_time": "2023-10-01T09:04:49.907956600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting file with index 0\n",
      "Predicting file with index 10\n",
      "Predicting file with index 20\n",
      "Predicting file with index 30\n",
      "Predicting file with index 40\n",
      "Predicting file with index 50\n",
      "Predicting file with index 60\n",
      "Predicting file with index 70\n",
      "Predicting file with index 80\n",
      "Predicting file with index 90\n",
      "Predicting file with index 100\n",
      "Predicting file with index 110\n",
      "Predicting file with index 120\n",
      "Predicting file with index 130\n",
      "Predicting file with index 140\n",
      "Predicting file with index 150\n",
      "Predicting file with index 160\n",
      "Predicting file with index 170\n",
      "Predicting file with index 180\n",
      "Predicting file with index 190\n",
      "Predicting file with index 200\n",
      "Predicting file with index 210\n",
      "Predicting file with index 220\n",
      "Predicting file with index 230\n",
      "Predicting file with index 240\n",
      "Predicting file with index 250\n",
      "Predicting file with index 260\n",
      "Predicting file with index 270\n",
      "Predicting file with index 280\n",
      "Predicting file with index 290\n",
      "Predicting file with index 300\n",
      "Predicting file with index 310\n",
      "Predicting file with index 320\n",
      "Predicting file with index 330\n",
      "Predicting file with index 340\n",
      "Predicting file with index 350\n",
      "Predicting file with index 360\n",
      "Predicting file with index 370\n",
      "Predicting file with index 380\n",
      "Predicting file with index 390\n",
      "Predicting file with index 400\n",
      "Predicting file with index 410\n",
      "Predicting file with index 420\n",
      "Predicting file with index 430\n",
      "Predicting file with index 440\n",
      "Predicting file with index 450\n",
      "Predicting file with index 460\n",
      "Predicting file with index 470\n",
      "Predicting file with index 480\n",
      "Predicting file with index 490\n",
      "Predicting file with index 500\n",
      "Predicting file with index 510\n",
      "Predicting file with index 520\n",
      "Predicting file with index 530\n",
      "Predicting file with index 540\n",
      "Predicting file with index 550\n",
      "Predicting file with index 560\n",
      "Predicting file with index 570\n",
      "Predicting file with index 580\n",
      "Predicting file with index 590\n",
      "Predicting file with index 600\n",
      "Predicting file with index 610\n",
      "Predicting file with index 620\n",
      "Predicting file with index 630\n",
      "Predicting file with index 640\n",
      "Predicting file with index 650\n",
      "Predicting file with index 660\n",
      "Predicting file with index 670\n",
      "Predicting file with index 680\n",
      "Predicting file with index 690\n",
      "Predicting file with index 700\n",
      "Predicting file with index 710\n",
      "Predicting file with index 720\n",
      "Predicting file with index 730\n",
      "Predicting file with index 740\n",
      "Predicting file with index 750\n",
      "Predicting file with index 760\n",
      "Predicting file with index 770\n",
      "Predicting file with index 780\n",
      "Predicting file with index 790\n",
      "Predicting file with index 800\n",
      "Predicting file with index 810\n",
      "Predicting file with index 820\n",
      "Predicting file with index 830\n",
      "Predicting file with index 840\n",
      "Predicting file with index 850\n",
      "Predicting file with index 860\n",
      "Predicting file with index 870\n",
      "Predicting file with index 880\n",
      "Predicting file with index 890\n",
      "Predicting file with index 900\n",
      "Predicting file with index 910\n",
      "Predicting file with index 920\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"data/test\"\n",
    "\n",
    "output_file = open(f\"solutions/solution_{run_id}.csv\", \"w\")\n",
    "output_file.write(\"Id,Category\\n\")\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for filename in os.listdir(root_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"Predicting file with index {idx}\")\n",
    "        idx += 1\n",
    "\n",
    "        img_path = os.path.join(root_dir, filename)\n",
    "        input_tensor = image_to_tensor(img_path)\n",
    "        output = model(input_tensor)\n",
    "\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "        predicted_label_idx = torch.argmax(probabilities).item()\n",
    "\n",
    "        output_file.write(f\"{filename},{all_labels[predicted_label_idx]}\\n\")\n",
    "\n",
    "output_file.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T09:05:01.623004400Z",
     "start_time": "2023-10-01T09:04:57.953235100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
